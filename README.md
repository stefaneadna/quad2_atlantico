# quad2_atlantico
CÃ³digos de trabalho do squad 2 AtlÃ¢ntico
Item 1 e 2 - Stefane e Pedrosa

item 3 e 4 - Ãcaro e Leandro

item 5 e 6 - Airton e Alberlando

Priscila, Elissandra


---

# AtlÃ¢ntico Bootcamp - ComputaÃ§Ã£o Cognitiva
## Projeto I

## NLP
### VisÃ£o Geral
Uma empresa contratante deseja estabelecer termos de maior relevÃ¢ncia em um documento especÃ­fico. Neste caso, considere o histÃ³rico de exames, consultas e procedimentos realizados por um paciente. Um sistema deve ser desenvolvido para que o mÃ©dico possa ter uma visÃ£o geral do histÃ³rico do paciente sem a necessidade de analisar documento por documento. Com base nesta importÃ¢ncia, vamos desenvolver uma etapa deste sistema. Tokenizar um texto, realizar remoÃ§Ã£o de stopwords, aplicar o processo de lematizaÃ§Ã£o e fazer uma anÃ¡lise quantitativa e visual subjetiva deste.

### Objetivos
1. Carregar o conjunto de documentos em PDF e armazenÃ¡-los em alguma estrutura de dados.
2. Realizar o prÃ©-processamento destes ( tokenizaÃ§Ã£o e remoÃ§Ã£o de stop words, deixar todos os caracteres minÃºsculos...).
3. LematizaÃ§Ã£o com a Lib stanza
4. Implementar para determinar as seguintes informaÃ§Ãµes dos resultados obtidos em 3:
4.1 Term Frequency (TF):
&nbsp;&nbsp;&nbsp;&nbsp;ğ‘‡ğ¹ = ğ‘ğ‘¡ğ‘‘ ğ‘‘ğ‘’ ğ‘œğ‘ğ‘œğ‘Ÿğ‘ŸÃªğ‘›ğ‘ğ‘–ğ‘ ğ‘‘ğ‘œ ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘œ ğ‘’ğ‘š ğ‘¢ğ‘š ğ‘¡ğ‘’ğ‘¥ğ‘¡ğ‘œ / ğ‘ğ‘¢ğ‘ğ‘›ğ‘¡ğ‘–ğ‘‘ğ‘ğ‘‘ğ‘’ ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘‘ğ‘’ ğ‘ğ‘ğ‘™ğ‘ğ‘£ğ‘Ÿğ‘ğ‘  ğ‘‘ğ‘œ ğ‘¡ğ‘’ğ‘¥ğ‘¡ğ‘œ
4.2 Document Frequency (DF)
&nbsp;&nbsp;&nbsp;&nbsp;ğ·ğ¹ = ğ‘ğ‘¡ğ‘‘ ğ‘‘ğ‘’ ğ‘œğ‘ğ‘œğ‘Ÿğ‘ŸÃªğ‘›ğ‘ğ‘–ğ‘ ğ‘‘ğ‘œ ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘œ ğ‘’ğ‘š ğ‘¢ğ‘š ğ‘ğ‘œğ‘›ğ‘—ğ‘¢ğ‘›ğ‘¡ğ‘œ ğ‘‘ğ‘’ ğ‘‘ğ‘œğ‘ğ‘¢ğ‘šğ‘’ğ‘›ğ‘¡ğ‘œğ‘ 
4.3 Inverse Document Frequency (IDF)
&nbsp;&nbsp;&nbsp;&nbsp;ğ¼ğ·ğ¹ = ğ‘™ğ‘œğ‘”(ğ‘ğ‘¡ğ‘‘ ğ‘‘ğ‘’ ğ‘‘ğ‘œğ‘ğ‘¢ğ‘šğ‘’ğ‘›ğ‘¡ğ‘œğ‘  / (ğ·ğ¹ + 1))
4.4 TF-IDF
&nbsp;&nbsp;&nbsp;&nbsp;ğ‘‡ğ¹ âˆ’ ğ¼ğ·ğ¹ = ğ¼ğ·ğ¹ * ğ‘‡ğ¹
4.5 Lista de strings com proximidade atÃ© 2 dos 5 termos de maior TF-IDF. Essas strings devem ser acompanhadas de seu valor de TF. Exemplo: Suponha que a lista dos 5 termos demaior TF-IDF Ã© [ casa, carro, comida, cachorro, gato]. Carro em um uma frase pode ter pneu e banco com as palavras mais prÃ³ximas. Em outra parte do texto, carro pode ter volante e cinto, como as palavras mais prÃ³ximas. Neste caso, para o termo carro, as strings pneu,banco,volante,cinto] sÃ£o as que devem ser armazenadas para anÃ¡lise.
5. Gerar um arquivo csv que possui todas as palavras de todos os documentos na primeira coluna, em que cada linha Ã© um token. Para cada token, informe nas colunas vizinhas as informaÃ§Ãµes determinadas no objetivo 4.1 atÃ© 4.4.
6. Gerar nuvem de palavras para anÃ¡lise visual tal como exemplo abaixo. Cada ponto central serÃ¡ um dos 5 termos de maior TF-IDF. As conexÃµes sÃ£o as palavras prÃ³ximas obtidas em 4.5. O tamanho do cÃ­rculo da palavra Ã© baseado no TF dela. O maior cÃ­rculo que conecta o termo central serÃ¡ normalizado para palavras de maior TF do conjunto.

![NÃºvem de palavras](/img/wordcloud.png)


**TÃ³picos de AuxÃ­lio**
https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-worlddataset-796d339a4089

**InformaÃ§Ãµes sobre as mÃ©tricas utilizadas**
https://www.kaggle.com/arthurtok/ghastly-network-and-d3-js-force-directed-graphs

**Atividade determinaÃ§Ã£o da nuvem de palavras**
http://andrewtrick.com/stormlight_network.html